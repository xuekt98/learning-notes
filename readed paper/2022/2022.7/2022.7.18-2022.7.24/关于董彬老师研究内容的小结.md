## 主要研究内容
董彬老师主要的研究内容是关于计算成像.  

术语 "计算成像"(Computational Imaging) 通常是指通过计算从测量中形成图像的过程.(the process of forming images from measurements via computations). 它包含两个重要的步骤: 第一步使用探测器或电磁束进行传感或扫描,  第二步使用数值算法重建图像. 董彬老师扩展了计算成像的定义, 让它也包括图像分析(Image Analysis).

于是计算成像就包含了三个部分:

第一部分传感(Sensing)是计算成像最基础的步骤, 这一步硬件的设计是研究的中心问题, 主要由采样的理论和算法支撑. 其主要目标是有效地获取成像对象的高质量测量值.  

第二部分是图像重建(Image Reconstruction), 其主要目标是从上一步获得的测量值中重建出高质量的图像. 这一步在之前的几十年主要靠数学方法实现, 现在有了深度学习的方法.  

第三部分是图像分析(Image Analysis), 其中数学和统计模型都发挥了重要作用, 图像分析的主要目的是从图像中提取有意义的信息以协助人类决策.  

尽管数学和统计模型在计算成像中取得了成功, 但是它们也面临着许多挑战.
1. 在Sensing过程中, 根据压缩感知的理论, 随机采样是一种很好的选择, 但是只有一部分的图像模态比如核磁共振成像, 满足这种理论的假设条件. 此外在没有考虑压缩感知理论的情况下, 应该有更好的感知机制来适应每一种主题. 一个好的自适应传感机制需要为每一个给定的成像对象决定要进行哪些测量以最大化特定的质量度量.  
2. 在图像重建过程中, 现有的模型和算法依赖于人类知道的先验的知识. 虽然我们知道对于每个模型, 哪类图像最适合, 但是对于一个给定的自然图像的集合, 很难手动的确定一个最适合的模型.  
3. 对于图像分析, 最终目标是提取相关的图像特征以方便决策. 在深度学习出现之前, 这些特征是手动给出的, 可能无法很好地适应数据集或底层图像分析任务.

## 两个主要阅读的内容
### 1. algorithm unrolling
这个部分主要研究如何将可迭代的算法展开成神经网络, 是传统算法与神经网络结合的一种形式, 这部分工作内容集中于CT相关的应用, 比如image segmentation (比较典型的比如Deep Active Contour Model), image Reconstruction 等应用.  

这个部分主要针对于计算成像的第二部分图像重建和第三部分图像分析的算法, 这种algorithm unrolling或者称作unrolled dynamics models(展开的动力学模型), 通常先要有一个迭代式的优化算法又或者是一个离散化的evolution PDE. 从而使得神经网络模型能够有更高的可解释性去支撑, 并且可以减少可学习的参数量, 以及提高网络的性能.  

### 2. PDE-Net相关内容
这个部分看的不太明白, 大体上看是类似于NeuralODE, 利用PDE来近似ResNet的block, 从而得到PDE的 $\delta t$ block, 与NeuralODE不同的地方是, PDE-Net中包含多个堆叠起来的 $\delta t$ block, 而NeuralODE只有一个ODE的block.  


## 一些想法和问题
1. 关于algorithm unrolling, 要把迭代的优化算法展开成神经网络的表示, 比如对于最原始的ISTA问题, 一般需要堆叠多少层的网络? 在这种有数学理论支撑的情况下, 是不是堆叠的越多越好? 还是和普通的神经网络一样, 堆叠过多也会很容易过拟合. 或者有没有一种最优的设计方式去设计这些堆叠的网络?

2. 现在Diffusion模型可以看做是基于ODE和SDE的生成模型, 有没有PDE相关的理论可以实现PDE为理论基础的生成模型.  

3. 关于Diffusion过程, 其前向和反向过程都可以看做是循环迭代的过程, 但是现在这些过程层数太多. algorithm unrolling是将循环优化算法展开成神经网络, 那么能不能反过来, 可以将可以将Diffusion的这些迭代的过程能够合并在一块.  

4. Diffusion去掉feature, PDE怎么保留feature
