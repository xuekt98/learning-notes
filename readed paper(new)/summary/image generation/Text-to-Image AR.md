#### 001. [Generative Pretraining From Pixels](https://proceedings.mlr.press/v119/chen20s/chen20s.pdf)

**ICML 2020**

![img](res/T2I%20AR/001-1.png)

iGPT is a significant work that brought Transformers into the realm of image generation. 尝试了sequential AR和BERT两种结构.

</br>


#### 002. [Zero-Shot Text-to-Image Generation](https://proceedings.mlr.press/v139/ramesh21a/ramesh21a.pdf)

**ICML 2021**

![img](res/T2I%20AR/002-1.png)

DALL-E包含了两个阶段的模型, 第一个阶段训练VQ-VAE, 第二个阶段训练Transformer.

</br>


#### 003. [CogView: Mastering Text-to-Image Generation via Transformers](https://proceedings.neurips.cc/paper_files/paper/2021/file/a4d92e2cd541fca87e4620aba658316d-Paper.pdf)

**NIPS 2021**

![img](res/T2I%20AR/003-1.png)

实现思路与DALL-E类似, 包含了两个阶段的模型, 第一阶段VQVAE对图像进行量化, 第二阶段Transformer.   

</br>


