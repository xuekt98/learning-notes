# T2I GAN

### 001-008 (~-2018)
The main research direction of text-to-image GAN before 2019 was incorporating text information into the generation process and generating high-resolution images. The main approach to input text condition was concatenating textual embeddings with the latent noise $z$ of GAN, and the widely used idea of higher resolution was multi-stage GAN.

### 009-014 (2019)
Most of the research in 2019 focused on incorporating more precise conditions into the generation process of GAN.  

### 015-018 (2020)
More rich and detailed text-to-image generation with higher quality.

### 019-023 (2021)
Rich context guided image generation, text-guided image manipulation

### 024-029 (2022)
Start to incorporate vision language models for image generation and manipulation, like CLIP. 

### 030-037 (2023 & 2024)
The main research direction is to improve the performance of GAN to be competitive with Diffusion models and incorporate more precise manipulation.  

</br>


# T2I AR

from 2022-2024, the research topic of AR gradually changes from generating image or video to multi-modal generation and understanding of text and visual contents.  


